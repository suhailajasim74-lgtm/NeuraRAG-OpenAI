<h1 align="center"> NeuraRAG â€“ OpenAI Powered Retrieval-Augmented Generation</h1>

<p align="center">
A lightweight and efficient RAG system that combines vector search, document embeddings, and generative AI to deliver accurate, context-aware answers from your custom knowledge base.
</p>

<hr>

<h2> <b>Project Overview</b></h2>
<p>
NeuraRAG is a Retrieval-Augmented Generation pipeline built using FAISS, MiniLM embeddings, and OpenAI GPT models. 
It enables intelligent question answering over custom documents by extracting text, chunking it, indexing embeddings, retrieving relevant context, and generating high-quality responses.
</p>

<hr>

<h2> <b>Core Features</b></h2>
<ul>
  <li><b>Document Ingestion</b> â€“ Supports PDFs, text files, and raw text.</li>
  <li><b>Text Chunking</b> â€“ Splits documents into optimized chunks for better embedding.</li>
  <li><b>Semantic Embeddings</b> â€“ Uses MiniLM / SentenceTransformer for fast, accurate embeddings.</li>
  <li><b>Vector Database</b> â€“ FAISS for efficient similarity search.</li>
  <li><b>Context Retrieval</b> â€“ Retrieves the top-k most relevant document sections.</li>
  <li><b>LLM Answer Generation</b> â€“ Uses OpenAI GPT models for final answer synthesis.</li>
  <li><b>Interactive Query Pipeline</b> â€“ Ask any question related to uploaded documents.</li>
</ul>

<hr>

<h2>ğŸ›  <b>Technologies Used</b></h2>
<ul>
  <li><b>Python</b></li>
  <li><b>FAISS</b> â€“ Vector search engine</li>
  <li><b>SentenceTransformers</b> (MiniLM embeddings)</li>
  <li><b>OpenAI GPT Models</b></li>
  <li><b>PyPDF2 / PDFMiner</b> â€“ PDF text extraction</li>
  <li><b>NumPy & Pandas</b></li>
</ul>

<hr>

<h2>ğŸ“ <b>Architecture Flow</b></h2>

<pre>
Document â†’ Text Extraction â†’ Chunking â†’ Embeddings â†’ FAISS Index â†’ Query â†’ Context Retrieval â†’ OpenAI â†’ Final Answer
</pre>

<hr>

<h2> <b>Input Types</b></h2>
<ul>
  <li>PDF files</li>
  <li>Plain text</li>
  <li>Custom text pasted directly</li>
</ul>

<h2> <b>Output Types</b></h2>
<ul>
  <li>Context-aware answers generated by OpenAI GPT</li>
  <li>Retrieved document snippets</li>
  <li>Embeddings stored in FAISS index</li>
</ul>

<hr>

<h2> <b>How It Works</b></h2>
<ol>
  <li><b>Load document</b> and extract text.</li>
  <li><b>Chunk</b> the text into manageable sections.</li>
  <li><b>Generate embeddings</b> using MiniLM.</li>
  <li><b>Index embeddings</b> in FAISS.</li>
  <li>When user asks something â†’ <b>query embedding</b>.</li>
  <li><b>Retrieve</b> top matches from FAISS.</li>
  <li>Send retrieved context + query to <b>OpenAI GPT model</b>.</li>
  <li><b>Return final answer</b>.</li>
</ol>

<hr>

<h2> <b>Example Query</b></h2>
<pre>
User: "What is the main objective of the document?"
System:
 - Retrieves similar passages
 - Sends to OpenAI
 - Generates summarized answer
</pre>

<hr>

<h2> <b>Use Cases</b></h2>
<ul>
  <li>Chatbot over internal documents</li>
  <li>Policy or handbook question answering</li>
  <li>Research paper summarization</li>
  <li>Automated knowledge assistants</li>
</ul>

<hr>

<h2> <b>License</b></h2>
<p>This project is open-source and free to use.</p>

<hr>

<h2 align="center">âœ¨ Built with â¤ï¸ using Generative AI âœ¨</h2>
